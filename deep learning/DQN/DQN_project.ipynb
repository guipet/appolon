{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "DQN_project_Guillaume.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J08X8_Bykl9J",
        "colab_type": "text"
      },
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7SPdSkQk9Zp",
        "colab_type": "code",
        "outputId": "e5ca5324-5db8-43c0-dc93-d87c358697bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "pip install scikit-video"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-video\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/a6/c69cad508139a342810ae46e946ebb3256aa6e42f690d901bb68f50582e3/scikit_video-1.1.11-py2.py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from scikit-video) (6.2.2)\n",
            "Installing collected packages: scikit-video\n",
            "Successfully installed scikit-video-1.1.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xTWG3-AlDIy",
        "colab_type": "code",
        "outputId": "5783cad0-2576-4bc7-f95b-08defedfc1e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        " pip install opencv-python"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N8R2I1akl9Q",
        "colab_type": "code",
        "outputId": "bdc8f9c8-714b-4639-b155-ae7714d0be7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import skvideo\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import sgd, adam\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization, Flatten"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wuzfRbIkl9e",
        "colab_type": "text"
      },
      "source": [
        "# MiniProject on Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCFmS5IJkl9j",
        "colab_type": "text"
      },
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKWpLwsqkl9l",
        "colab_type": "text"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-0bvGTdkl9n",
        "colab_type": "text"
      },
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPG_PnOJkl9p",
        "colab_type": "text"
      },
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEXSZ6yLkl9r",
        "colab_type": "text"
      },
      "source": [
        "### The environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8Dzgvb0kl9t",
        "colab_type": "text"
      },
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeSIvYkmkl9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67--SQR8kl95",
        "colab_type": "text"
      },
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzY601OXkl97",
        "colab_type": "text"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m74pRERWkl9_",
        "colab_type": "text"
      },
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAWtkpOwkl-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0LeFCwpkl-K",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZWtvxFMkl-L",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The function act implements the $\\epsilon$-greedy algorithm. At time $t$, the agent select with probability $\\epsilon$ an action randomly and with probability $1 - \\epsilon$, he chooses with respect to the policy. \n",
        "So, the higher $\\epsilon$ is, the more we encourage exploring. The lower $\\epsilon$ is, the more we encourage exploiting.\\\n",
        "$\\epsilon$ is essential because it makes the agent explore other possibilities during the training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99v25U0vkl-N",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpjBTAxgkl-O",
        "colab_type": "text"
      },
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urEiJErokl-Q",
        "colab_type": "text"
      },
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRoNNV-3kl-R",
        "colab_type": "text"
      },
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuRYx42Hkl-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[:,-2 :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[:,-2 :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P-kxd4Mkl-W",
        "colab_type": "text"
      },
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHNhatHEkl-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T    = 200\n",
        "temperature  = 0.3\n",
        "epochs_train = 15  # set small when debugging\n",
        "epochs_test  = 15  # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaMqyJ-wkl-g",
        "colab_type": "text"
      },
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhV-p1nAkl-i",
        "colab_type": "text"
      },
      "source": [
        "```position``` : the array has 3 states. 1 for the actual position of the rat on the grid, -1 where the rat can go and 0 where he can't go.\n",
        "\n",
        "```board``` : it represents the reward of the grid cells. So the reward of cell choosen by the rat.\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RYP-2RRkl-k",
        "colab_type": "text"
      },
      "source": [
        "## Random Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s57kV7Wjkl-l",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdK5vGLQkl-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        '''\n",
        "        Input:\n",
        "        - s : état \n",
        "        Output : \n",
        "        - a : action\n",
        "        '''\n",
        "        \n",
        "        a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "        return (a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14tYmwWSkl-q",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlHTPlX3kl-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(agent , env, epochs, prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will end\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state, train = False)  #we are during the test\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            \n",
        "        # Save as a mp4\n",
        "        if e % 5 == 0:\n",
        "            env.draw(prefix + str(e))\n",
        "        #env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDMZ4rMOkl-u",
        "colab_type": "code",
        "outputId": "f7011814-25a1-4882-b024-f90681dca32d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 10.0/12.0. Average score (-2.0)\n",
            "Win/lose count 6.5/8.0. Average score (-1.75)\n",
            "Win/lose count 12.5/24.0. Average score (-5.0)\n",
            "Win/lose count 8.5/16.0. Average score (-5.625)\n",
            "Win/lose count 8.0/17.0. Average score (-6.3)\n",
            "Win/lose count 6.0/13.0. Average score (-6.416666666666667)\n",
            "Win/lose count 12.5/9.0. Average score (-5.0)\n",
            "Win/lose count 7.0/15.0. Average score (-5.375)\n",
            "Win/lose count 6.5/14.0. Average score (-5.611111111111111)\n",
            "Win/lose count 9.5/11.0. Average score (-5.2)\n",
            "Win/lose count 11.0/9.0. Average score (-4.545454545454546)\n",
            "Win/lose count 15.5/23.0. Average score (-4.791666666666667)\n",
            "Win/lose count 13.0/17.0. Average score (-4.730769230769231)\n",
            "Win/lose count 8.5/14.0. Average score (-4.785714285714286)\n",
            "Win/lose count 10.5/12.0. Average score (-4.566666666666666)\n",
            "Final score: -4.566666666666666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAGGxtZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9MyBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAALdZYiEADf//vaH+BTZWBP+Wb/9DX/cj9uPrP1xYyEE31qvIejAGS+1H+b/rFFs6Z6UB/fgCJQAc24ZwpHZJ46w5MIvVHwKXAT74FNJkUf192yR0ErYiSrz23w5hsLTM9OWXP/1GSNw24nylUJSO87VoZ61z25end6mhD1T84OB25DbDKFUg6Raq6siNicyVoi99D3sRHDVnnHOYWbhNDQ/AKMqlzPoFBs5OaVDEi+KoavDSKal2wtqtsin+0ILVtFknlZ2hMaoyRyQ1bzE92rBqJBN+sXWewHMF+euqW9uORa0h6iisvkFsOqWCbPxOG+vnVfZ3DuBnsQvsv8nDJoBt2c0HFSRU+xafwHuB0fnCbdvUFq38yGOFKeiRU5RiRm/kNVVQZfmyF6pmtDFihVH42tETPkGquwuTC22ljovpy2Lm3cWnmIus3nxv/i+flOz7958k7VSe1VkYv/ncNQWHZ4xDJMDSAwAQAElhURM6OU9bQsG2tOX+oVHOX1cp2rzLgRyyzjI7Mb55X8ysF0ZCdh9CDkLFgOCQHtE98S6z9KN3/hGaVbwqcMJ0yfbYrH7o515vGqOvWXGUP6jmACQLLDATF9rQ0bj6eKZAjAuyQkOiE6oaSIsI7t/Tacrm+7yQTmqAS9ovflzbJLNMGZK50ErwssRZJvxsl3GBbmJu9qzyaClHOv9RsRy4ueZaJA/yUBSpqZi4iGR/Gjja78c6iVrjKfERQqbQhgRDeA9I+E2UTV7ripxi0V/KtGfkTmYrmteyISI1CBXFKqAHYmS6jSM+985UHYid4dN1lcjEKiAtcoxUO/ygBPNVOSDchVAD9YTZT2gEyeDmyinOiGqM684+jwqaYYrEfIixPd594ezMrtXLLu834Obm8/rzVPLCui2eHNQCaJK+vcGpzxMAT93142ryJQlBIvDVEa32QdRXoes0WcvYV1L0heXKfc08zWsN3Egz9MG7AAR0QAAABRBmiFsQ7/+qZYAArvvqzH2bZiigAAAABtBmkU8IZMphDf//qeEAAVH3U/ary2fCjW6JtMAAAAPQZ5jalPC/wADJKtG0n8sAAAADwGegnRCvwAENtGLgPz5wQAAAA8BnoRqQr8ABDZW6UaQ82cAAAAcQZqHSahBaJlMFPDv/qmWAAKBpZygzQKfRj9QDwAAABABnqZqQr8ABBXmiZE0rVJBAAAAGUGaqknhClJlMCHf/qmWAAKTpZXGaX9sVcAAAAASQZ7IRTRMK/8ABkoaXeYwdq88AAAADwGe6WpCvwAGSJkmpoHr4QAAAB5Bmu5JqEFomUwId//+qZYABACjogWZ29X3x1S7sUAAAAAQQZ8MRREsL/8ABNZ61xdbIAAAABABnyt0Qr8ABppFlXgRXnWBAAAADwGfLWpCvwAGmsWBdf424QAAABpBmzJJqEFsmUwId//+qZYABAfjz+XaR5z3gQAAABBBn1BFFSwv/wAE1z9m4JBwAAAADwGfb3RCvwAGweTeecZbgAAAAA8Bn3FqQr8ABpiWlSKBLHMAAAASQZt2SahBbJlMCG///qeEAAEnAAAAE0GflEUVLC//AAMREtymY+YiLMIAAAAQAZ+zdEK/AAQ3cd5Wyh8ygQAAABABn7VqQr8ABDXmiZE0rU9AAAAAGkGbuEmoQWyZTBRMN//+p4QABSPdT91vjvVdAAAAEAGf12pCvwAEFlkMPoCQf9kAAAARQZvcSeEKUmUwIb/+p4QAAScAAAATQZ/6RTRML/8AAzfrj29uHBLsRQAAAA8Bnhl0Qr8ABFfSdwbJevYAAAAPAZ4bakK/AARWVulGkPNXAAAAHEGaHkmoQWiZTBTw3/6nhAAFGxWzE/1dvdT9t7kAAAAQAZ49akK/AAQXaITcZ9eyyAAAABxBmiBJ4QpSZTBSw3/+p4QABSPdT9zIwtmKEdJEAAAAEAGeX2pCvwAEFk+c60MMRIEAAAAYQZpBSeEOiZTAhv/+p4QAAzvsHr2Z8EbDAAAAFkGaZUnhDyZTAhv//qeEAAMPYNWZKckAAAAOQZ6DRRE8L/8AAc/99KAAAAAPAZ6idEK/AAKHZRxHZdpvAAAAEAGepGpCvwAD424Dn9aB07kAAAAZQZqmSahBaJlMCG///qeEAAMn7B69mfBGywAAABhBmshJ4QpSZTBREsO//qmWAAGC9pf1wkEAAAAPAZ7nakK/AAJ9ygeTBSeAAAAAGkGa7EnhDomUwIb//qeEAAc845D1aBfGn1h4AAAAFUGfCkUVPC//AARXP2amZZchwmEbZQAAABABnyl0Qr8AA7cZkR2LMVQIAAAAEAGfK2pCvwAF+dU8mB6+iYAAAAAdQZsuSahBaJlMFPDf/qeEAAc9PDrg2qZCex09wmsAAAAQAZ9NakK/AAX4mSab6SD3EQAAABxBm1JJ4QpSZTAhv/6nhAAE2+mJ/7rSzNTbovCxAAAAEEGfcEU0TC//AALoyxUIRTAAAAAQAZ+PdEK/AAP42BraZQ+dwAAAAA8Bn5FqQr8AA/hqHQtHHcEAAAAaQZuTSahBaJlMCG///qeEAANK6tIIRP8umoAAAAAdQZu1SeEKUmUwURLDv/6plgACpaWYtM0B3fRj2OsAAAAPAZ/UakK/AAQ3Z5bhs2uDAAAAGEGb2UnhDomUwId//qmWAAKp76vvRQDKhwAAABBBn/dFFTwv/wADJKu7/O8xAAAADwGeFnRCvwAGmsq7vN4CQQAAAA8BnhhqQr8ABDZW6UaQ82YAAAAaQZocSahBaJlMCHf//qmWAAGq9peFqCf2QMEAAAARQZ46RREsK/8AAsVKN5oWEVMAAAAOAZ5bakK/AALE2MZNzGcAAAAaQZpfSahBbJlMCHf//qmWAAKB8gzQB6S+3XEAAAASQZ59RRUsK/8AA/jO+hbki2+AAAAAEAGenmpCvwAD+MweTA9feIAAAAAaQZqCSahBbJlMCHf//qmWAAPQmQk3Dgo+fzEAAAAPQZ6gRRUsK/8ABkiWs4pAAAAADwGewWpCvwAGcBY2BypQgQAAACtBmsZJqEFsmUwIb//+p4QAEm+mGr4FNfUK/ApUtn4FM7AxdvNF1npW80EgAAAAFUGe5EUVLC//AAsVAgo/n0WLb6XMpQAAABABnwN0Qr8ACbCAOdscacqhAAAAEAGfBWpCvwAO2zB5MD18DYEAAAAZQZsJSahBbJlMCG///qeEABxDjP9SkArVwQAAAA9BnydFFSwr/wAXRtwJbcAAAAAOAZ9IakK/ABcLKO+9cW4AAAAdQZtLSahBbJlMFEw3//6nhAAcb2D+fBSt0WCf8RkAAAAPAZ9qakK/ABdGspm2ZGzdAAAAGEGbbknhClJlMCG//qeEABuXVo6qG25fgAAAABFBn4xFNEwr/wAWuwrBISt/GQAAAA4Bn61qQr8AFrsTFcCYZQAAABpBm7FJqEFomUwIb//+p4QAG799n1HGhIc7oQAAABFBn89FESwr/wAXSlG803vVMwAAAA4Bn/BqQr8AF0bGPRFeegAAAB1Bm/NJqEFsmUwUTDf//qeEABHvjp91pZmpt0W6WQAAABABnhJqQr8ADoBEzTfSQdTwAAAAGUGaFknhClJlMCG//qeEAAv/sH+E4LdCtsAAAAAPQZ40RTRMK/8ACayuBOjBAAAADQGeVWpCvwAJsGsPF0YAAAAZQZpZSahBaJlMCG///qeEAAef2D17M+CL9wAAAA9BnndFESwr/wAGSI0DqkEAAAAOAZ6YakK/AAZKwTnPMaoAAAAZQZqaSahBbJlMCG///qeEAAdz2D17M+CL/wAAAB1BmrxJ4QpSZTBRUsN//qeEAAdH32fcyMLZihHQPAAAABABnttqQr8ABfiO3OtDDB9BAAAAHEGa3knhDomUwUTDv/6plgACU/Hn8zQqBaKYiWcAAAAQAZ79akK/AAO2ETNN9JCBcAAAABlBmuFJ4Q8mUwId//6plgACYIsN0YhHPt7QAAAAEkGfH0URPCv/AAPMz5lvDchAeQAAAA8BnyBqQr8AA8zPmN/BBuAAAAASQZslSahBaJlMCG///qeEAAEnAAAADEGfQ0URLC//AACygAAAABABn2J0Qr8ABfrKu6vx3j5BAAAAEAGfZGpCvwADwqG9itH3aYEAAAASQZtpSahBbJlMCG///qeEAAEnAAAADEGfh0UVLC//AACygQAAABABn6Z0Qr8ABfrKu6vx3j5AAAAADwGfqGpCvwADwqG7DPVo6QAAABpBm6pJqEFsmUwIb//+p4QABzzjP9VvmPx44QAAABtBm81J4QpSZTAhv/6nhAALZ7qfutLMeRUuchcAAAASQZ/rRTRMK/8ACS9Ou8xg7VwUAAAAEAGeDGpCvwAJbmjeaYq21sEAAAAaQZoOSahBaJlMCG///qeEAAeUHhTrOn3XuYEAAAARQZoySeEKUmUwIb/+p4QAAScAAAAMQZ5QRTRML/8AALKAAAAAEAGeb3RCvwAGceTdHbfDg4AAAAAPAZ5xakK/AAY3OTdZ6tDVAAAAGkGac0moQWiZTAhv//6nhAAHwB4U6zp917OAAAAAGUGalknhClJlMCG//qeEAAw9In+q3zH4w8AAAAAPQZ60RTRMK/8ACfNuBOZBAAAADQGe1WpCvwAJ9ysPFzIAAAAgQZrYSahBaJlMFPDf/qeEABNR8zU2YVc3JnX2e/ZdTIMAAAAQAZ73akK/AA+LMHkwPXwEgQAAABlBmvlJ4QpSZTAh3/6plgAO6mQk3Dgo+bgQAAAALUGbHUnhDomUwId//qmWABlviE5XmWVTtG8Cl/Xh4E6o6Qk4u3JLP7UfEeN0wQAAAB9BnztFETwv/wAdtNjfTU5llMUY5lgHg5lkG6NT8qUwAAAAEAGfWnRCvwAmvmqB07UOA4EAAAAQAZ9cakK/ACj2EeS5nyVggQAAABlBm0BJqEFomUwId//+qZYAJwiw3RTgg1T4AAAAD0GffkURLCv/AD4g/5qD4AAAAA0Bn59qQr8APjYFA0vnAAAAIEGbhEmoQWyZTAhv//6nhABNvpdAhP51H6F2tmKEfqAgAAAAEEGfokUVLC//AC6MeQxcrgkAAAAQAZ/BdEK/AD4cUXAfZzJAYAAAAA8Bn8NqQr8APM/A6FridzkAAAAgQZvISahBbJlMCGf//p4QAc8pxzG+r891ff4zvXRmZtEAAAARQZ/mRRUsL/8AR3PGa/av7tEAAAAQAZ4FdEK/AF+kr31/aa+5IQAAABABngdqQr8AYgFjX1QdPLqYAAAAHEGaCUmoQWyZTAhn//6eEALBwY5/DnxAUz9Zb0AAAAAZQZoqSeEKUmUwIb/+p4QAuWK0dH3GzBXXcQAAAB5BmkxJ4Q6JlMFNEw3//qeEAL77qffDPETM1NukMQcAAAAQAZ5rakK/AJrmjeaYq2kIwAAAABlBmm1J4Q8mUwIb//6nhAB5/YP8JwW6El3BAAAAGEGakEnhDyZTAhv//qeEAFGxWkEIn+W3MwAAAA9Bnq5FETwr/wBBZNw1+kEAAAANAZ7PakK/AEGDSLev0gAAAB5BmtRJqEFomUwIZ//+nhABRu+DVAX380rKtxbJH+AAAAAQQZ7yRREsL/8AMkHoaQe7sQAAABABnxF0Qr8AQ3cd5Wyh6WaAAAAADwGfE2pCvwAtdKN6rAC/4AAAABlBmxVJqEFsmUwIb//+p4QANj7B69mfBFhBAAAAGEGbNknhClJlMCG//qeEADT+wevZnwRYSQAAABtBm1pJ4Q6JlMCGf/6eEAEtEOdNgvRHX39MAsEAAAAQQZ94RRE8L/8ALpQIrSildQAAAA8Bn5d0Qr8AP5YrGEKtesAAAAAQAZ+ZakK/AD4s+Y3Q5IOPzQAAABlBm5tJqEFomUwIb//+p4QATb46Y/w+rbdDAAAAGEGbvknhClJlMCGf/p4QAcQpxz+HOb6zWwAAABFBn9xFNEwr/wBfnaf9HJFVFwAAABABn/1qQr8AX51TyYHr29mAAAAAHEGb/0moQWiZTAhn//6eEALBwY5/DnxAUz9Zb0AAAAAXQZoASeEKUmUwIb/+p4QAuWK0dVDbbQsAAAAZQZohSeEOiZTAhv/+p4QBHEAWbbZ9nzRQQAAAABxBmkNJ4Q8mUwURPDf//qeEAR36OfHbehnGKfPhAAAAEAGeYmpCvwDngvOdaGF4i8AAAAARQZpnSeEPJlMCG//+p4QAAScAAAASQZ6FRRE8L/8AbCJbngk49IxdAAAAEAGepHRCvwCSu1J5X5KbNlEAAAAQAZ6makK/AJLtEJuM+vTbKQAAABlBmqhJqEFomUwIb//+p4QAtfupx/h9W20TAAAAG0GayUnhClJlMCG//qeEALF8foE769mfBFdiwAAAAB1Bmu1J4Q6JlMCG//6nhAEEH5REEAZcbL04P98H+QAAABBBnwtFETwv/wCfMeQVeDxsAAAADwGfKnRCvwDX2Vd3m7UZwAAAABABnyxqQr8A14LGveaVm0vBAAAAGUGbL0moQWiZTBTw3/6nhAD9+wf55RQd4+8AAAAQAZ9OakK/ANezc1x4q2j0IQAAABlBm1BJ4QpSZTAh3/6plgBXffV9diDcU/xwAAAAHEGbdEnhDomUwIb//qeEAKeANWZO/YP6sHnC5UAAAAAVQZ+SRRE8L/8AZJV4zYSgHfTOQiPhAAAAEAGfsXRCvwBa01oyS3+t8cAAAAAQAZ+zakK/AIbs8cr+3D6xwAAAABpBm7VJqEFomUwId//+qZYAgCLDdGIRz6/l4QAAABJBm9lJ4QpSZTAh3/6plgAAlYAAAAAMQZ/3RTRML/8AALKBAAAAEAGeFnRCvwFI6Ac/rQORwsEAAAAQAZ4YakK/AUiNrushhyOFgAAAABJBmh1JqEFomUwIb//+p4QAAScAAAAMQZ47RREsL/8AALKAAAAAEAGeWnRCvwDQZycR2XZU3oEAAAAPAZ5cakK/ANBnJus9WemBAAAAGkGaQEmoQWyZTAhv//6nhAD9+wf4Tgt0JFlAAAAAEUGefkUVLCv/ANezc1x73qEDAAAADwGen2pCvwDXktKkUCVR6QAAAB5BmoJJqEFsmUwUTDf//qeEAKh7qfd5uvvrZihH6GUAAAAQAZ6hakK/AIbJ851oYXi/gQAAABhBmqVJ4QpSZTAhn/6eEAGd9ffyJEfWEg4AAAAPQZ7DRTRMK/8AVltwJOvBAAAADgGe5GpCvwBWeVL+ByT3AAAAGkGa6UuoQhBaJEYIKAfyAf2HgCFf/jhAABFxAAAAI0GfB0URLC//AgHc6kvbMwq5gOgatahcCUAZaJPC3zKTNJwxAAAADwGfJnRCvwA4rYGh5zy7ZQAAACYBnyhqQr8Cr2PtQcTdqsNJJuWqhgcstbz0wE4lpdo4uvDNPk6+sAAAC9Btb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAfkAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAK+nRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAfkAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAABEAAAARAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAH5AAAAQAAAEAAAAACnJtZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAADIAAAGUAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAodbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAJ3XN0YmwAAACVc3RzZAAAAAAAAAABAAAAhWF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAABEAEQAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAvYXZjQwH0AA3/4QAXZ/QADZGbKCIR0IAAAAMAgAAAGQeKFMsBAAVo6+PESAAAABhzdHRzAAAAAAAAAAEAAADKAAACAAAAABRzdHNzAAAAAAAAAAEAAAABAAAFqGN0dHMAAAAAAAAAswAAAAIAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAgAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAACAAAAAACAAACAAAAAAMAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAgAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAAcc3RzYwAAAAAAAAABAAAAAQAAAMoAAAABAAADPHN0c3oAAAAAAAAAAAAAAMoAAAWSAAAAGAAAAB8AAAATAAAAEwAAABMAAAAgAAAAFAAAAB0AAAAWAAAAEwAAACIAAAAUAAAAFAAAABMAAAAeAAAAFAAAABMAAAATAAAAFgAAABcAAAAUAAAAFAAAAB4AAAAUAAAAFQAAABcAAAATAAAAEwAAACAAAAAUAAAAIAAAABQAAAAcAAAAGgAAABIAAAATAAAAFAAAAB0AAAAcAAAAEwAAAB4AAAAZAAAAFAAAABQAAAAhAAAAFAAAACAAAAAUAAAAFAAAABMAAAAeAAAAIQAAABMAAAAcAAAAFAAAABMAAAATAAAAHgAAABUAAAASAAAAHgAAABYAAAAUAAAAHgAAABMAAAATAAAALwAAABkAAAAUAAAAFAAAAB0AAAATAAAAEgAAACEAAAATAAAAHAAAABUAAAASAAAAHgAAABUAAAASAAAAIQAAABQAAAAdAAAAEwAAABEAAAAdAAAAEwAAABIAAAAdAAAAIQAAABQAAAAgAAAAFAAAAB0AAAAWAAAAEwAAABYAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAATAAAAHgAAAB8AAAAWAAAAFAAAAB4AAAAVAAAAEAAAABQAAAATAAAAHgAAAB0AAAATAAAAEQAAACQAAAAUAAAAHQAAADEAAAAjAAAAFAAAABQAAAAdAAAAEwAAABEAAAAkAAAAFAAAABQAAAATAAAAJAAAABUAAAAUAAAAFAAAACAAAAAdAAAAIgAAABQAAAAdAAAAHAAAABMAAAARAAAAIgAAABQAAAAUAAAAEwAAAB0AAAAcAAAAHwAAABQAAAATAAAAFAAAAB0AAAAcAAAAFQAAABQAAAAgAAAAGwAAAB0AAAAgAAAAFAAAABUAAAAWAAAAFAAAABQAAAAdAAAAHwAAACEAAAAUAAAAEwAAABQAAAAdAAAAFAAAAB0AAAAgAAAAGQAAABQAAAAUAAAAHgAAABYAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAATAAAAHgAAABUAAAATAAAAIgAAABQAAAAcAAAAEwAAABIAAAAeAAAAJwAAABMAAAAqAAAAFHN0Y28AAAAAAAAAAQAAADAAAABidWR0YQAAAFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU3LjgzLjEwMA==\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgq2QXvwkl-1",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU8Ph1lCkl-2",
        "colab_type": "text"
      },
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJU1E82ykl-3",
        "colab_type": "text"
      },
      "source": [
        "$\\bf{\\underline{ First \\hspace{0.1cm} question :}} $\n",
        "\n",
        "$$\n",
        "Q^{\\pi}(s,a) = E_{p^\\pi}[\\sum_{t\\leq T} \\gamma^{t} r(s_t,a_t)|s_0 = s, a_0 = a]\\\\\n",
        "= E_{p^\\pi}[  r(s,a) + \\gamma\\sum_{t=1}^{T} \\gamma^{t-1} r(s_t,a_t)|s_0 = s, a_0 = a]\\\\\n",
        "= r(s,a) + \\gamma \\sum_{s'}\\sum_{a'}p(s_1 = s',a_1 = a'|s_0,a_0)E[\\sum_{t=1}^{T}\\gamma^{t-1}r(s_t,a_t)|s_1 = s', a_1 = a']\\\\\n",
        "= r(s,a) + \\gamma\\sum_{s'}\\sum_{a'}p(s',a'|s_0,a_0)Q^{\\pi}(s',a')\\\\\n",
        "=r(s,a) + \\gamma E_{s',a'\\sim p(.|s,a)}[Q^{\\pi}(s',a')]\n",
        "$$\n",
        "\n",
        "$\\bf{\\underline{ Second \\hspace{0.1cm} question :}} $\n",
        "\n",
        "$$\n",
        "Q^{*}(s,a) = \\max_{\\pi}E_{p^\\pi}[\\sum_{t\\leq T} \\gamma^{t} r(s_t,a_t)|s_0 = s, a_0 = a]\\\\\n",
        "= \\max_{\\pi'} ( r(s,a) + \\gamma \\sum_{s'}\\sum_{a'}p(s',a'|s_0,a_0)Q^{\\pi'}(s',a')) \\\\\n",
        "= r(s,a) + \\gamma \\sum_{s'}\\sum_{a'}p(s',a'|s_0,a_0)\\max_{\\pi'}Q^{\\pi'}(s',a') \\\\\n",
        "= r(s,a) + \\gamma \\sum_{s'}\\sum_{a'}p(s',a'|s_0,a_0)Q^{*}(s',a') \\\\\n",
        "= E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')]\n",
        "$$\n",
        "\n",
        "$\\bf{\\underline{ Third \\hspace{0.1cm} question :}}$\n",
        "We can recognize the mean square error \n",
        "$$\n",
        "\\mathcal{L}(\\theta)= E[(\\hat{\\theta} - \\theta)^{2}]\\\\\n",
        "E_{s' \\sim \\pi^*(.|s,a)}[\\Vert Q^{*}(s,a,\\theta^{*})-Q(s,a,\\theta)\\Vert^{2}\\Vert^{2}]\\\\\n",
        "E_{s' \\sim \\pi^*(.|s,a)}[\\Vert r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}]\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVO-dvtXkl-4",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSRH4-i6kl-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        self.memory.append(m)\n",
        "        if len(self.memory) > self.max_memory:\n",
        "            del self.memory[0]\n",
        "\n",
        "    def random_access(self):\n",
        "        i = np.random.choice( len(self.memory) )\n",
        "        return self.memory[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjy3dC4Kkl-7",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYHQJ3RPkl-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLQLzOY1kl--",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAZK3vNokl-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        s = np.expand_dims(s,axis=0)\n",
        "        a = np.argmax(self.model.predict(s))\n",
        "        return a\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            \n",
        "            state1, state2, action, reward, game_over = self.memory.random_access()\n",
        "            target_q[i] = self.model.predict(np.expand_dims(state1, axis = 0))\n",
        "            input_states[i,:,:,:] = state1\n",
        "            state2 = np.expand_dims(state2, axis = 0)  \n",
        "            \n",
        "            if game_over_:\n",
        "                target_q[i,action] = reward\n",
        "                \n",
        "            else:\n",
        "                target_q[i,action] = reward + self.discount*np.max(self.model.predict(state2))\n",
        "        \n",
        "        \n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model\n",
        "        model = Sequential()\n",
        "        model.add(Flatten(input_shape=(5,5,self.n_state,)))\n",
        "        model.add(Dense(25,activation ='relu'))\n",
        "        model.add(Dense(4))\n",
        "        \n",
        "        model.compile(adam(lr=lr, decay=1e-4), \"mse\")\n",
        "        self.model = model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOnDdoHgkl_C",
        "colab_type": "code",
        "outputId": "b4e22ba4-49b5-4074-f2ab-128c4e7db7d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=.001, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train10.mp4'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 000/015 | Loss 0.2619 | Win/lose count 6.5/7.0 (-0.5)\n",
            "Epoch 001/015 | Loss 0.8054 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 002/015 | Loss 1.3416 | Win/lose count 5.5/4.0 (1.5)\n",
            "Epoch 003/015 | Loss 1.5485 | Win/lose count 6.5/3.0 (3.5)\n",
            "Epoch 004/015 | Loss 1.7216 | Win/lose count 8.5/6.0 (2.5)\n",
            "Epoch 005/015 | Loss 1.6899 | Win/lose count 4.0/4.0 (0.0)\n",
            "Epoch 006/015 | Loss 1.8797 | Win/lose count 4.5/1.0 (3.5)\n",
            "Epoch 007/015 | Loss 1.8333 | Win/lose count 2.5/0 (2.5)\n",
            "Epoch 008/015 | Loss 1.8046 | Win/lose count 2.5/1.0 (1.5)\n",
            "Epoch 009/015 | Loss 1.8442 | Win/lose count 7.5/4.0 (3.5)\n",
            "Epoch 010/015 | Loss 1.8868 | Win/lose count 6.5/2.0 (4.5)\n",
            "Epoch 011/015 | Loss 2.0120 | Win/lose count 9.0/9.0 (0.0)\n",
            "Epoch 012/015 | Loss 1.9469 | Win/lose count 8.0/2.0 (6.0)\n",
            "Epoch 013/015 | Loss 1.9409 | Win/lose count 5.5/3.0 (2.5)\n",
            "Epoch 014/015 | Loss 1.9410 | Win/lose count 2.5/4.0 (-1.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zecCdhwAkl_G",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDuPuvl4kl_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(50,(2,2),input_shape=(5,5,self.n_state,),activation='relu'))\n",
        "        model.add(Conv2D(30,(2,2),activation='relu'))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4))\n",
        "        \n",
        "        model.compile(adam(lr=lr, decay=1e-4), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDrribf8kl_K",
        "colab_type": "code",
        "outputId": "8c1ac480-3778-4b38-cd5c-c0feb3f663d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.001, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train10.mp4'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/015 | Loss 2.1390 | Win/lose count 0.5/1.0 (-0.5)\n",
            "Epoch 001/015 | Loss 2.1079 | Win/lose count 6.5/3.0 (3.5)\n",
            "Epoch 002/015 | Loss 1.8665 | Win/lose count 15.0/9.0 (6.0)\n",
            "Epoch 003/015 | Loss 1.9484 | Win/lose count 9.0/6.0 (3.0)\n",
            "Epoch 004/015 | Loss 1.9087 | Win/lose count 7.0/3.0 (4.0)\n",
            "Epoch 005/015 | Loss 1.8500 | Win/lose count 13.5/3.0 (10.5)\n",
            "Epoch 006/015 | Loss 1.9044 | Win/lose count 13.5/6.0 (7.5)\n",
            "Epoch 007/015 | Loss 1.9240 | Win/lose count 6.5/3.0 (3.5)\n",
            "Epoch 008/015 | Loss 1.8043 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 009/015 | Loss 1.8782 | Win/lose count 4.0/0 (4.0)\n",
            "Epoch 010/015 | Loss 1.8313 | Win/lose count 5.5/3.0 (2.5)\n",
            "Epoch 011/015 | Loss 1.8253 | Win/lose count 14.0/4.0 (10.0)\n",
            "Epoch 012/015 | Loss 1.8517 | Win/lose count 6.0/4.0 (2.0)\n",
            "Epoch 013/015 | Loss 1.9366 | Win/lose count 12.5/1.0 (11.5)\n",
            "Epoch 014/015 | Loss 1.8515 | Win/lose count 17.5/3.0 (14.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aPSSq9ckl_N",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zflCoqKakl_O",
        "colab_type": "code",
        "outputId": "bea13e01-c992-4f9c-dca7-ca9d2d434d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.5)\n",
        "agent_cnn = DQN_CNN(size, lr=.001, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.001, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n",
            "Win/lose count 3.0/0. Average score (3.0)\n",
            "Win/lose count 1.5/0. Average score (2.25)\n",
            "Win/lose count 0.5/0. Average score (1.6666666666666667)\n",
            "Win/lose count 0.5/0. Average score (1.375)\n",
            "Win/lose count 6.0/1.0. Average score (2.1)\n",
            "Win/lose count 0.5/0. Average score (1.8333333333333333)\n",
            "Win/lose count 1.0/0. Average score (1.7142857142857142)\n",
            "Win/lose count 8.5/2.0. Average score (2.3125)\n",
            "Win/lose count 0.5/0. Average score (2.111111111111111)\n",
            "Win/lose count 0.5/0. Average score (1.95)\n",
            "Win/lose count 0.5/0. Average score (1.8181818181818181)\n",
            "Win/lose count 3.5/1.0. Average score (1.875)\n",
            "Win/lose count 1.5/0. Average score (1.8461538461538463)\n",
            "Win/lose count 0.5/0. Average score (1.75)\n",
            "Win/lose count 2.0/0. Average score (1.7666666666666666)\n",
            "Final score: 1.7666666666666666\n",
            "Test of the FC\n",
            "Win/lose count 0.5/1.0. Average score (-0.5)\n",
            "Win/lose count 2.0/2.0. Average score (-0.25)\n",
            "Win/lose count 0.5/1.0. Average score (-0.3333333333333333)\n",
            "Win/lose count 1.0/1.0. Average score (-0.25)\n",
            "Win/lose count 1.5/0. Average score (0.1)\n",
            "Win/lose count 1.0/3.0. Average score (-0.25)\n",
            "Win/lose count 2.5/5.0. Average score (-0.5714285714285714)\n",
            "Win/lose count 7.0/4.0. Average score (-0.125)\n",
            "Win/lose count 0/1.0. Average score (-0.2222222222222222)\n",
            "Win/lose count 1.5/1.0. Average score (-0.15)\n",
            "Win/lose count 1.5/3.0. Average score (-0.2727272727272727)\n",
            "Win/lose count 2.0/3.0. Average score (-0.3333333333333333)\n",
            "Win/lose count 1.0/1.0. Average score (-0.3076923076923077)\n",
            "Win/lose count 4.5/0. Average score (0.03571428571428571)\n",
            "Win/lose count 0.5/0. Average score (0.06666666666666667)\n",
            "Final score: 0.06666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00H-FWLSkl_R",
        "colab_type": "code",
        "outputId": "5323775a-696f-41b4-ee90-8e26de92c00d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "HTML(display_videos('cnn_test10.mp4'))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfDxIcCAkl_W",
        "colab_type": "code",
        "outputId": "f91f726d-ccf9-4b41-abcc-619727eba2be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "HTML(display_videos('fc_test10.mp4'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb8_Wd4okl_Z",
        "colab_type": "text"
      },
      "source": [
        "| Temperature       |    score CNN    |      score  FC |\n",
        "| :------------: | :-------------: | :-------------: |\n",
        "| 0.1       |     1.06      |       -0.23  |\n",
        "| 0.2       |     1.3       |        -0.16 |\n",
        "| 0.3       |     2.1       |        -0.14 |\n",
        "| 0.4       |     1.9       |        -0.13 |\n",
        "| 0.5       |     2.8       |         0.1  |\n",
        "| 0.6       |     2.13      |         0.3  |\n",
        "| 0.7       |     3.26      |         0.6  |\n",
        "| 0.8       |     4.63      |         1.2  |\n",
        "| 0.9       |     6.83      |         2.2  |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haRM38sOkl_Z",
        "colab_type": "text"
      },
      "source": [
        "On remarque 3 faits importants : \\\n",
        " • Le score du CNN semble plus performant que celui du FC.\\\n",
        " • Les scores semblent augmenter au fur et à mesure que la température augmente.\\\n",
        " • A partir d'un moment, la souris finit par ne plus explorer la grille et fait des boucles. Cela se produit plus facilement lorsque le rat ne voit pas de récompense, c'est-à-dire que la température diminue.\n",
        " \n",
        "L'architecture du CNN prend en partie en compte la spatialité de la grille en connectant les voisins d'une cellule aux mêmes poids. Plus la températur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pbgPp-Tkl_a",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH5jNPGWkl_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_explore(agent,env,epoch,decay_parameter_epsilon=0.3,prefix=''):\n",
        "    #New training procedure that tries to improve the exploration of the algorithm\n",
        "    #decay_parameter_epsilon in order to use the decreasing $\\epsilon$-greedy exploration\n",
        "    \n",
        "    \n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "    decay_parameter_epsilon = 0.5\n",
        "    print(\"epsilon\",agent.epsilon)\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "        if e % 5 == 0 and e!= 0:\n",
        "            agent.set_epsilon(agent.epsilon*(decay_parameter_epsilon))\n",
        "            print(\"epsilon\",agent.epsilon)\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
        "        \n",
        "class EnvironmentExploring(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "        self.malus_position = np.zeros((grid_size,grid_size)) #define maluses when going to a previously visited position\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action,train=False):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "        #During the training phase going back to a position where the rat have already been before tends to decrease the \n",
        "        #total reward hence there is this train parameter that we have added (it tries to enforce the exploration)\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.malus_position = np.zeros((self.grid_size,self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[:, -2:] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1     \n",
        "        \n",
        "        ## In Environment exploring:\n",
        "        # You will have to change n_state to 3 because you will use one more layer!\n",
        "        reward = 0\n",
        "        if train:\n",
        "            reward = -self.malus_position[self.x, self.y]\n",
        "        self.malus_position[self.x, self.y] = 1\n",
        "\n",
        "        reward = reward + self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        \n",
        "        # 3 \"feature\" states instead of 2\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[:,-2:] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
        "        #At the begining the malus_position array must be setted to zero\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0WlVx4kkl_g",
        "colab_type": "code",
        "outputId": "48302da7-28ae-49c0-9f96-207d5f3be35e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.5)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.9, memory_size=2000, batch_size = 32,n_state=3)\n",
        "train_explore(agent, env, 50, prefix='cnn_train_explore')\n",
        "HTML(display_videos('cnn_train_explore10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epsilon 0.9\n",
            "Epoch 000/050 | Loss 1.4063 | Win/lose count 17.5/21.0 (-3.5)\n",
            "Epoch 001/050 | Loss 2.0478 | Win/lose count 20.0/16.0 (4.0)\n",
            "Epoch 002/050 | Loss 1.9163 | Win/lose count 18.0/12.0 (6.0)\n",
            "Epoch 003/050 | Loss 2.1192 | Win/lose count 24.5/17.0 (7.5)\n",
            "Epoch 004/050 | Loss 2.0720 | Win/lose count 16.5/16.0 (0.5)\n",
            "epsilon 0.45\n",
            "Epoch 005/050 | Loss 2.1792 | Win/lose count 13.0/10.0 (3.0)\n",
            "Epoch 006/050 | Loss 1.9919 | Win/lose count 15.0/10.0 (5.0)\n",
            "Epoch 007/050 | Loss 2.1410 | Win/lose count 16.5/7.0 (9.5)\n",
            "Epoch 008/050 | Loss 1.8797 | Win/lose count 21.5/14.0 (7.5)\n",
            "Epoch 009/050 | Loss 1.9649 | Win/lose count 12.5/18.0 (-5.5)\n",
            "epsilon 0.225\n",
            "Epoch 010/050 | Loss 1.9665 | Win/lose count 12.0/10.0 (2.0)\n",
            "Epoch 011/050 | Loss 2.1402 | Win/lose count 18.5/11.0 (7.5)\n",
            "Epoch 012/050 | Loss 1.9226 | Win/lose count 11.5/13.0 (-1.5)\n",
            "Epoch 013/050 | Loss 1.8931 | Win/lose count 3.5/9.0 (-5.5)\n",
            "Epoch 014/050 | Loss 1.9688 | Win/lose count 10.0/8.0 (2.0)\n",
            "epsilon 0.1125\n",
            "Epoch 015/050 | Loss 2.1476 | Win/lose count 5.0/10.0 (-5.0)\n",
            "Epoch 016/050 | Loss 1.9119 | Win/lose count 10.0/6.0 (4.0)\n",
            "Epoch 017/050 | Loss 2.0340 | Win/lose count 14.5/8.0 (6.5)\n",
            "Epoch 018/050 | Loss 1.8615 | Win/lose count 10.0/1.0 (9.0)\n",
            "Epoch 019/050 | Loss 1.9327 | Win/lose count 19.0/11.0 (8.0)\n",
            "epsilon 0.05625\n",
            "Epoch 020/050 | Loss 2.0088 | Win/lose count 14.0/2.0 (12.0)\n",
            "Epoch 021/050 | Loss 1.8676 | Win/lose count 10.0/8.0 (2.0)\n",
            "Epoch 022/050 | Loss 1.8086 | Win/lose count 15.5/13.0 (2.5)\n",
            "Epoch 023/050 | Loss 1.8083 | Win/lose count 13.5/11.0 (2.5)\n",
            "Epoch 024/050 | Loss 1.8187 | Win/lose count 14.5/6.0 (8.5)\n",
            "epsilon 0.028125\n",
            "Epoch 025/050 | Loss 1.8120 | Win/lose count 22.5/14.0 (8.5)\n",
            "Epoch 026/050 | Loss 1.8557 | Win/lose count 29.0/19.0 (10.0)\n",
            "Epoch 027/050 | Loss 1.9822 | Win/lose count 8.5/7.0 (1.5)\n",
            "Epoch 028/050 | Loss 1.8598 | Win/lose count 14.5/12.0 (2.5)\n",
            "Epoch 029/050 | Loss 1.9416 | Win/lose count 13.5/10.0 (3.5)\n",
            "epsilon 0.0140625\n",
            "Epoch 030/050 | Loss 1.6962 | Win/lose count 8.0/3.0 (5.0)\n",
            "Epoch 031/050 | Loss 1.7348 | Win/lose count 13.5/4.0 (9.5)\n",
            "Epoch 032/050 | Loss 1.7572 | Win/lose count 13.5/8.0 (5.5)\n",
            "Epoch 033/050 | Loss 1.8030 | Win/lose count 16.5/12.0 (4.5)\n",
            "Epoch 034/050 | Loss 1.7914 | Win/lose count 9.5/16.0 (-6.5)\n",
            "epsilon 0.00703125\n",
            "Epoch 035/050 | Loss 1.9286 | Win/lose count 15.5/18.0 (-2.5)\n",
            "Epoch 036/050 | Loss 1.7395 | Win/lose count 10.5/6.0 (4.5)\n",
            "Epoch 037/050 | Loss 1.8788 | Win/lose count 12.5/9.0 (3.5)\n",
            "Epoch 038/050 | Loss 1.7060 | Win/lose count 5.5/0 (5.5)\n",
            "Epoch 039/050 | Loss 1.8337 | Win/lose count 8.5/9.0 (-0.5)\n",
            "epsilon 0.003515625\n",
            "Epoch 040/050 | Loss 1.8716 | Win/lose count 12.0/9.0 (3.0)\n",
            "Epoch 041/050 | Loss 1.7812 | Win/lose count 16.5/14.0 (2.5)\n",
            "Epoch 042/050 | Loss 1.7997 | Win/lose count 6.0/9.0 (-3.0)\n",
            "Epoch 043/050 | Loss 1.5665 | Win/lose count 15.0/23.0 (-8.0)\n",
            "Epoch 044/050 | Loss 1.6579 | Win/lose count 16.5/28.0 (-11.5)\n",
            "epsilon 0.0017578125\n",
            "Epoch 045/050 | Loss 1.6227 | Win/lose count 18.0/17.0 (1.0)\n",
            "Epoch 046/050 | Loss 1.6127 | Win/lose count 16.0/18.0 (-2.0)\n",
            "Epoch 047/050 | Loss 1.7480 | Win/lose count 23.0/20.0 (3.0)\n",
            "Epoch 048/050 | Loss 1.5235 | Win/lose count 16.0/19.0 (-3.0)\n",
            "Epoch 049/050 | Loss 1.8078 | Win/lose count 15.0/6.0 (9.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S1aVxoTkl_j",
        "colab_type": "code",
        "outputId": "9e06542c-5ff2-43fd-de5f-772b9b60b5d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "source": [
        "# Evaluation\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore10.mp4'))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 8.5/0. Average score (8.5)\n",
            "Win/lose count 4.5/0. Average score (6.5)\n",
            "Win/lose count 15.0/0. Average score (9.333333333333334)\n",
            "Win/lose count 7.0/0. Average score (8.75)\n",
            "Win/lose count 7.0/0. Average score (8.4)\n",
            "Win/lose count 5.5/0. Average score (7.916666666666667)\n",
            "Win/lose count 6.0/0. Average score (7.642857142857143)\n",
            "Win/lose count 3.0/0. Average score (7.0625)\n",
            "Win/lose count 20.5/0. Average score (8.555555555555555)\n",
            "Win/lose count 13.5/0. Average score (9.05)\n",
            "Win/lose count 4.0/0. Average score (8.590909090909092)\n",
            "Win/lose count 7.0/1.0. Average score (8.375)\n",
            "Win/lose count 2.0/0. Average score (7.884615384615385)\n",
            "Win/lose count 13.0/1.0. Average score (8.178571428571429)\n",
            "Win/lose count 15.0/0. Average score (8.633333333333333)\n",
            "Final score: 8.633333333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8A3SfoAkl_l",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2AFlFnEkl_m",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flXopDiHkl_n",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    }
  ]
}