{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3_Petit_Guillaume.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln7sdg7zo9-X",
        "colab_type": "code",
        "outputId": "fc29c1bf-ddf0-4bdc-851f-0777e745c8eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!pip install torch torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "1.3.1\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOBT7ZM9pA-L",
        "colab_type": "code",
        "outputId": "4b8c43ea-ab7e-458d-c935-77cbcccc3e9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://www.di.ens.fr/willow/teaching/recvis18/assignment3/bird_dataset.zip"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-26 18:56:43--  https://www.di.ens.fr/willow/teaching/recvis18/assignment3/bird_dataset.zip\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘bird_dataset.zip.1’\n",
            "\n",
            "bird_dataset.zip.1      [   <=>              ] 183.48M  30.0MB/s    in 6.2s    \n",
            "\n",
            "2019-11-26 18:56:49 (29.7 MB/s) - ‘bird_dataset.zip.1’ saved [192388716]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFrxwoP0pC6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"bird_dataset.zip\",'r') as zip_ref:\n",
        "  zip_ref.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeksAQ2npHGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "#import pretrainedmodels\n",
        "\n",
        "# once the images are loaded, how do we pre-process them before being passed into the network\n",
        "# by default, we resize the images to 64 x 64 in size\n",
        "# and normalize them to mean = 0 and standard-deviation = 1 based on statistics collected from\n",
        "# the training set\n",
        "data_train_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomPerspective(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "data_val_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxRZHawvpJwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "nclasses = 20 \n",
        "\n",
        "#notre modèle\n",
        "model = models.resnet152(pretrained= True)\n",
        "\n",
        "#on freeze\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "\n",
        "number_features = model.fc.in_features\n",
        "\n",
        "model.fc = nn.Linear(number_features, 20)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpy0n41cpNYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "from tqdm import tqdm\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YdqoejYpRCI",
        "colab_type": "code",
        "outputId": "a3c8a443-a598-4a91-e6d9-5d1bec190d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training settings\n",
        "#parser = argparse.ArgumentParser(description='RecVis A3 training script')\n",
        "#parser.add_argument('--data', type=str, default='bird_dataset', metavar='D',\n",
        "#                    help=\"folder where data is located. train_images/ and val_images/ need to be found in the folder\")\n",
        "#parser.add_argument('--batch-size', type=int, default=64, metavar='B',\n",
        "#                    help='input batch size for training (default: 64)')\n",
        "#parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
        "#                    help='number of epochs to train (default: 10)')\n",
        "#parser.add_argument('--lr', type=float, default=0.1, metavar='LR',\n",
        "#                    help='learning rate (default: 0.01)')\n",
        "#parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
        "#                    help='SGD momentum (default: 0.5)')\n",
        "#parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
        "#                    help='random seed (default: 1)')\n",
        "#arser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
        "#                    help='how many batches to wait before logging training status')\n",
        "#parser.add_argument('--experiment', type=str, default='experiment', metavar='E',\n",
        "#                    help='folder where experiment outputs are located.')\n",
        "\n",
        "#args = parser.parse_args()\n",
        "use_cuda = torch.cuda.is_available()\n",
        "#torch.manual_seed(args.seed)\n",
        "\n",
        "# Create experiment folder\n",
        "if not os.path.isdir(\"nouveau\"):\n",
        "    os.makedirs(\"nouveau\")\n",
        "\n",
        "# Data initialization and loading\n",
        "#from data import data_transforms\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.ImageFolder('bird_dataset' + '/train_images',\n",
        "                         transform=data_train_transforms),\n",
        "    batch_size= 32, shuffle=True, num_workers=1)\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    datasets.ImageFolder('bird_dataset' + '/val_images',\n",
        "                         transform=data_val_transforms),\n",
        "    batch_size= 32, shuffle=False, num_workers=1)\n",
        "\n",
        "# Neural network and optimizer\n",
        "# We define neural net in model.py so that it can be reused by the evaluate.py script\n",
        "#from model import Net\n",
        "model = model\n",
        "if use_cuda:\n",
        "    print('Using GPU')\n",
        "    model.cuda()\n",
        "else:\n",
        "    print('Using CPU')\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
        "\n",
        "def validation():\n",
        "    model.eval()\n",
        "    validation_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in val_loader:\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        output = model(data)\n",
        "        # sum up batch loss\n",
        "        criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "        validation_loss += criterion(output, target).data.item()\n",
        "        # get the index of the max log-probability\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    validation_loss /= len(val_loader.dataset)\n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "        validation_loss, correct, len(val_loader.dataset),\n",
        "        100. * correct / len(val_loader.dataset)))\n",
        "\n",
        "\n",
        "for epoch in range(1, 50 + 1):\n",
        "    train(epoch)\n",
        "    validation()\n",
        "    model_file = \"nouveau\" + '/model_' + str(epoch) + '.pth'\n",
        "    torch.save(model.state_dict(), model_file)\n",
        "    print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')\n",
        "    "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU\n",
            "Train Epoch: 1 [0/1082 (0%)]\tLoss: 3.090602\n",
            "Train Epoch: 1 [320/1082 (29%)]\tLoss: 3.068284\n",
            "Train Epoch: 1 [640/1082 (59%)]\tLoss: 2.937843\n",
            "Train Epoch: 1 [960/1082 (88%)]\tLoss: 2.904269\n",
            "\n",
            "Validation set: Average loss: 0.1034, Accuracy: 24/103 (23%)\n",
            "Saved model to nouveau/model_1.pth. You can run `python evaluate.py --model nouveau/model_1.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 2 [0/1082 (0%)]\tLoss: 2.793746\n",
            "Train Epoch: 2 [320/1082 (29%)]\tLoss: 2.667759\n",
            "Train Epoch: 2 [640/1082 (59%)]\tLoss: 2.516579\n",
            "Train Epoch: 2 [960/1082 (88%)]\tLoss: 2.379550\n",
            "\n",
            "Validation set: Average loss: 0.0889, Accuracy: 45/103 (44%)\n",
            "Saved model to nouveau/model_2.pth. You can run `python evaluate.py --model nouveau/model_2.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 3 [0/1082 (0%)]\tLoss: 2.456465\n",
            "Train Epoch: 3 [320/1082 (29%)]\tLoss: 2.419438\n",
            "Train Epoch: 3 [640/1082 (59%)]\tLoss: 2.190546\n",
            "Train Epoch: 3 [960/1082 (88%)]\tLoss: 2.351699\n",
            "\n",
            "Validation set: Average loss: 0.0791, Accuracy: 61/103 (59%)\n",
            "Saved model to nouveau/model_3.pth. You can run `python evaluate.py --model nouveau/model_3.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 4 [0/1082 (0%)]\tLoss: 2.355886\n",
            "Train Epoch: 4 [320/1082 (29%)]\tLoss: 2.012240\n",
            "Train Epoch: 4 [640/1082 (59%)]\tLoss: 1.998974\n",
            "Train Epoch: 4 [960/1082 (88%)]\tLoss: 2.038035\n",
            "\n",
            "Validation set: Average loss: 0.0712, Accuracy: 71/103 (69%)\n",
            "Saved model to nouveau/model_4.pth. You can run `python evaluate.py --model nouveau/model_4.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 5 [0/1082 (0%)]\tLoss: 2.089737\n",
            "Train Epoch: 5 [320/1082 (29%)]\tLoss: 1.900903\n",
            "Train Epoch: 5 [640/1082 (59%)]\tLoss: 1.654744\n",
            "Train Epoch: 5 [960/1082 (88%)]\tLoss: 1.935763\n",
            "\n",
            "Validation set: Average loss: 0.0623, Accuracy: 77/103 (75%)\n",
            "Saved model to nouveau/model_5.pth. You can run `python evaluate.py --model nouveau/model_5.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 6 [0/1082 (0%)]\tLoss: 1.668924\n",
            "Train Epoch: 6 [320/1082 (29%)]\tLoss: 1.964322\n",
            "Train Epoch: 6 [640/1082 (59%)]\tLoss: 1.762327\n",
            "Train Epoch: 6 [960/1082 (88%)]\tLoss: 1.652769\n",
            "\n",
            "Validation set: Average loss: 0.0553, Accuracy: 76/103 (74%)\n",
            "Saved model to nouveau/model_6.pth. You can run `python evaluate.py --model nouveau/model_6.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 7 [0/1082 (0%)]\tLoss: 1.742654\n",
            "Train Epoch: 7 [320/1082 (29%)]\tLoss: 1.818397\n",
            "Train Epoch: 7 [640/1082 (59%)]\tLoss: 1.769358\n",
            "Train Epoch: 7 [960/1082 (88%)]\tLoss: 1.657779\n",
            "\n",
            "Validation set: Average loss: 0.0527, Accuracy: 80/103 (78%)\n",
            "Saved model to nouveau/model_7.pth. You can run `python evaluate.py --model nouveau/model_7.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 8 [0/1082 (0%)]\tLoss: 1.640384\n",
            "Train Epoch: 8 [320/1082 (29%)]\tLoss: 1.570500\n",
            "Train Epoch: 8 [640/1082 (59%)]\tLoss: 1.659359\n",
            "Train Epoch: 8 [960/1082 (88%)]\tLoss: 1.530133\n",
            "\n",
            "Validation set: Average loss: 0.0471, Accuracy: 79/103 (77%)\n",
            "Saved model to nouveau/model_8.pth. You can run `python evaluate.py --model nouveau/model_8.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 9 [0/1082 (0%)]\tLoss: 1.171516\n",
            "Train Epoch: 9 [320/1082 (29%)]\tLoss: 1.381420\n",
            "Train Epoch: 9 [640/1082 (59%)]\tLoss: 1.342114\n",
            "Train Epoch: 9 [960/1082 (88%)]\tLoss: 1.632734\n",
            "\n",
            "Validation set: Average loss: 0.0444, Accuracy: 80/103 (78%)\n",
            "Saved model to nouveau/model_9.pth. You can run `python evaluate.py --model nouveau/model_9.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 10 [0/1082 (0%)]\tLoss: 1.234814\n",
            "Train Epoch: 10 [320/1082 (29%)]\tLoss: 1.644704\n",
            "Train Epoch: 10 [640/1082 (59%)]\tLoss: 1.177072\n",
            "Train Epoch: 10 [960/1082 (88%)]\tLoss: 1.327351\n",
            "\n",
            "Validation set: Average loss: 0.0447, Accuracy: 83/103 (81%)\n",
            "Saved model to nouveau/model_10.pth. You can run `python evaluate.py --model nouveau/model_10.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 11 [0/1082 (0%)]\tLoss: 1.148087\n",
            "Train Epoch: 11 [320/1082 (29%)]\tLoss: 1.327768\n",
            "Train Epoch: 11 [640/1082 (59%)]\tLoss: 1.267245\n",
            "Train Epoch: 11 [960/1082 (88%)]\tLoss: 1.436748\n",
            "\n",
            "Validation set: Average loss: 0.0419, Accuracy: 78/103 (76%)\n",
            "Saved model to nouveau/model_11.pth. You can run `python evaluate.py --model nouveau/model_11.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 12 [0/1082 (0%)]\tLoss: 1.303346\n",
            "Train Epoch: 12 [320/1082 (29%)]\tLoss: 1.380739\n",
            "Train Epoch: 12 [640/1082 (59%)]\tLoss: 1.626825\n",
            "Train Epoch: 12 [960/1082 (88%)]\tLoss: 1.407334\n",
            "\n",
            "Validation set: Average loss: 0.0397, Accuracy: 81/103 (79%)\n",
            "Saved model to nouveau/model_12.pth. You can run `python evaluate.py --model nouveau/model_12.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 13 [0/1082 (0%)]\tLoss: 1.458205\n",
            "Train Epoch: 13 [320/1082 (29%)]\tLoss: 1.079593\n",
            "Train Epoch: 13 [640/1082 (59%)]\tLoss: 1.249336\n",
            "Train Epoch: 13 [960/1082 (88%)]\tLoss: 1.223741\n",
            "\n",
            "Validation set: Average loss: 0.0367, Accuracy: 80/103 (78%)\n",
            "Saved model to nouveau/model_13.pth. You can run `python evaluate.py --model nouveau/model_13.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 14 [0/1082 (0%)]\tLoss: 1.132128\n",
            "Train Epoch: 14 [320/1082 (29%)]\tLoss: 1.355798\n",
            "Train Epoch: 14 [640/1082 (59%)]\tLoss: 1.094184\n",
            "Train Epoch: 14 [960/1082 (88%)]\tLoss: 0.958349\n",
            "\n",
            "Validation set: Average loss: 0.0365, Accuracy: 80/103 (78%)\n",
            "Saved model to nouveau/model_14.pth. You can run `python evaluate.py --model nouveau/model_14.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 15 [0/1082 (0%)]\tLoss: 1.245696\n",
            "Train Epoch: 15 [320/1082 (29%)]\tLoss: 1.189231\n",
            "Train Epoch: 15 [640/1082 (59%)]\tLoss: 1.371718\n",
            "Train Epoch: 15 [960/1082 (88%)]\tLoss: 1.004540\n",
            "\n",
            "Validation set: Average loss: 0.0350, Accuracy: 82/103 (80%)\n",
            "Saved model to nouveau/model_15.pth. You can run `python evaluate.py --model nouveau/model_15.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 16 [0/1082 (0%)]\tLoss: 1.319419\n",
            "Train Epoch: 16 [320/1082 (29%)]\tLoss: 1.177206\n",
            "Train Epoch: 16 [640/1082 (59%)]\tLoss: 1.389822\n",
            "Train Epoch: 16 [960/1082 (88%)]\tLoss: 1.421990\n",
            "\n",
            "Validation set: Average loss: 0.0349, Accuracy: 80/103 (78%)\n",
            "Saved model to nouveau/model_16.pth. You can run `python evaluate.py --model nouveau/model_16.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 17 [0/1082 (0%)]\tLoss: 1.231578\n",
            "Train Epoch: 17 [320/1082 (29%)]\tLoss: 1.169263\n",
            "Train Epoch: 17 [640/1082 (59%)]\tLoss: 1.124365\n",
            "Train Epoch: 17 [960/1082 (88%)]\tLoss: 1.076581\n",
            "\n",
            "Validation set: Average loss: 0.0341, Accuracy: 83/103 (81%)\n",
            "Saved model to nouveau/model_17.pth. You can run `python evaluate.py --model nouveau/model_17.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 18 [0/1082 (0%)]\tLoss: 1.136970\n",
            "Train Epoch: 18 [320/1082 (29%)]\tLoss: 1.235944\n",
            "Train Epoch: 18 [640/1082 (59%)]\tLoss: 1.117400\n",
            "Train Epoch: 18 [960/1082 (88%)]\tLoss: 0.926222\n",
            "\n",
            "Validation set: Average loss: 0.0339, Accuracy: 81/103 (79%)\n",
            "Saved model to nouveau/model_18.pth. You can run `python evaluate.py --model nouveau/model_18.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 19 [0/1082 (0%)]\tLoss: 1.147166\n",
            "Train Epoch: 19 [320/1082 (29%)]\tLoss: 1.504311\n",
            "Train Epoch: 19 [640/1082 (59%)]\tLoss: 0.909030\n",
            "Train Epoch: 19 [960/1082 (88%)]\tLoss: 1.377496\n",
            "\n",
            "Validation set: Average loss: 0.0329, Accuracy: 83/103 (81%)\n",
            "Saved model to nouveau/model_19.pth. You can run `python evaluate.py --model nouveau/model_19.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 20 [0/1082 (0%)]\tLoss: 1.017695\n",
            "Train Epoch: 20 [320/1082 (29%)]\tLoss: 0.869668\n",
            "Train Epoch: 20 [640/1082 (59%)]\tLoss: 0.975626\n",
            "Train Epoch: 20 [960/1082 (88%)]\tLoss: 1.035856\n",
            "\n",
            "Validation set: Average loss: 0.0313, Accuracy: 80/103 (78%)\n",
            "Saved model to nouveau/model_20.pth. You can run `python evaluate.py --model nouveau/model_20.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 21 [0/1082 (0%)]\tLoss: 1.274469\n",
            "Train Epoch: 21 [320/1082 (29%)]\tLoss: 0.910879\n",
            "Train Epoch: 21 [640/1082 (59%)]\tLoss: 1.164499\n",
            "Train Epoch: 21 [960/1082 (88%)]\tLoss: 1.091937\n",
            "\n",
            "Validation set: Average loss: 0.0300, Accuracy: 82/103 (80%)\n",
            "Saved model to nouveau/model_21.pth. You can run `python evaluate.py --model nouveau/model_21.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 22 [0/1082 (0%)]\tLoss: 1.016217\n",
            "Train Epoch: 22 [320/1082 (29%)]\tLoss: 0.930454\n",
            "Train Epoch: 22 [640/1082 (59%)]\tLoss: 1.267974\n",
            "Train Epoch: 22 [960/1082 (88%)]\tLoss: 1.027696\n",
            "\n",
            "Validation set: Average loss: 0.0300, Accuracy: 83/103 (81%)\n",
            "Saved model to nouveau/model_22.pth. You can run `python evaluate.py --model nouveau/model_22.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 23 [0/1082 (0%)]\tLoss: 1.205065\n",
            "Train Epoch: 23 [320/1082 (29%)]\tLoss: 0.927755\n",
            "Train Epoch: 23 [640/1082 (59%)]\tLoss: 1.083396\n",
            "Train Epoch: 23 [960/1082 (88%)]\tLoss: 0.972910\n",
            "\n",
            "Validation set: Average loss: 0.0308, Accuracy: 81/103 (79%)\n",
            "Saved model to nouveau/model_23.pth. You can run `python evaluate.py --model nouveau/model_23.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 24 [0/1082 (0%)]\tLoss: 1.174302\n",
            "Train Epoch: 24 [320/1082 (29%)]\tLoss: 0.808591\n",
            "Train Epoch: 24 [640/1082 (59%)]\tLoss: 1.138248\n",
            "Train Epoch: 24 [960/1082 (88%)]\tLoss: 0.700489\n",
            "\n",
            "Validation set: Average loss: 0.0294, Accuracy: 81/103 (79%)\n",
            "Saved model to nouveau/model_24.pth. You can run `python evaluate.py --model nouveau/model_24.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 25 [0/1082 (0%)]\tLoss: 0.898296\n",
            "Train Epoch: 25 [320/1082 (29%)]\tLoss: 0.854104\n",
            "Train Epoch: 25 [640/1082 (59%)]\tLoss: 0.686307\n",
            "Train Epoch: 25 [960/1082 (88%)]\tLoss: 1.054668\n",
            "\n",
            "Validation set: Average loss: 0.0274, Accuracy: 83/103 (81%)\n",
            "Saved model to nouveau/model_25.pth. You can run `python evaluate.py --model nouveau/model_25.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 26 [0/1082 (0%)]\tLoss: 1.047091\n",
            "Train Epoch: 26 [320/1082 (29%)]\tLoss: 0.997586\n",
            "Train Epoch: 26 [640/1082 (59%)]\tLoss: 1.039207\n",
            "Train Epoch: 26 [960/1082 (88%)]\tLoss: 1.196579\n",
            "\n",
            "Validation set: Average loss: 0.0299, Accuracy: 80/103 (78%)\n",
            "Saved model to nouveau/model_26.pth. You can run `python evaluate.py --model nouveau/model_26.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 27 [0/1082 (0%)]\tLoss: 1.323950\n",
            "Train Epoch: 27 [320/1082 (29%)]\tLoss: 0.959019\n",
            "Train Epoch: 27 [640/1082 (59%)]\tLoss: 0.807245\n",
            "Train Epoch: 27 [960/1082 (88%)]\tLoss: 0.974386\n",
            "\n",
            "Validation set: Average loss: 0.0290, Accuracy: 81/103 (79%)\n",
            "Saved model to nouveau/model_27.pth. You can run `python evaluate.py --model nouveau/model_27.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 28 [0/1082 (0%)]\tLoss: 0.594534\n",
            "Train Epoch: 28 [320/1082 (29%)]\tLoss: 0.706887\n",
            "Train Epoch: 28 [640/1082 (59%)]\tLoss: 1.219244\n",
            "Train Epoch: 28 [960/1082 (88%)]\tLoss: 1.103650\n",
            "\n",
            "Validation set: Average loss: 0.0262, Accuracy: 81/103 (79%)\n",
            "Saved model to nouveau/model_28.pth. You can run `python evaluate.py --model nouveau/model_28.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 29 [0/1082 (0%)]\tLoss: 0.847331\n",
            "Train Epoch: 29 [320/1082 (29%)]\tLoss: 1.181039\n",
            "Train Epoch: 29 [640/1082 (59%)]\tLoss: 1.087767\n",
            "Train Epoch: 29 [960/1082 (88%)]\tLoss: 0.914324\n",
            "\n",
            "Validation set: Average loss: 0.0285, Accuracy: 79/103 (77%)\n",
            "Saved model to nouveau/model_29.pth. You can run `python evaluate.py --model nouveau/model_29.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 30 [0/1082 (0%)]\tLoss: 1.041222\n",
            "Train Epoch: 30 [320/1082 (29%)]\tLoss: 0.877388\n",
            "Train Epoch: 30 [640/1082 (59%)]\tLoss: 0.808730\n",
            "Train Epoch: 30 [960/1082 (88%)]\tLoss: 1.299973\n",
            "\n",
            "Validation set: Average loss: 0.0280, Accuracy: 80/103 (78%)\n",
            "Saved model to nouveau/model_30.pth. You can run `python evaluate.py --model nouveau/model_30.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 31 [0/1082 (0%)]\tLoss: 0.926278\n",
            "Train Epoch: 31 [320/1082 (29%)]\tLoss: 0.848406\n",
            "Train Epoch: 31 [640/1082 (59%)]\tLoss: 0.694000\n",
            "Train Epoch: 31 [960/1082 (88%)]\tLoss: 0.633109\n",
            "\n",
            "Validation set: Average loss: 0.0273, Accuracy: 80/103 (78%)\n",
            "Saved model to nouveau/model_31.pth. You can run `python evaluate.py --model nouveau/model_31.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 32 [0/1082 (0%)]\tLoss: 0.772538\n",
            "Train Epoch: 32 [320/1082 (29%)]\tLoss: 1.025132\n",
            "Train Epoch: 32 [640/1082 (59%)]\tLoss: 1.063898\n",
            "Train Epoch: 32 [960/1082 (88%)]\tLoss: 1.370766\n",
            "\n",
            "Validation set: Average loss: 0.0272, Accuracy: 79/103 (77%)\n",
            "Saved model to nouveau/model_32.pth. You can run `python evaluate.py --model nouveau/model_32.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 33 [0/1082 (0%)]\tLoss: 1.184165\n",
            "Train Epoch: 33 [320/1082 (29%)]\tLoss: 1.072071\n",
            "Train Epoch: 33 [640/1082 (59%)]\tLoss: 1.355491\n",
            "Train Epoch: 33 [960/1082 (88%)]\tLoss: 0.827994\n",
            "\n",
            "Validation set: Average loss: 0.0272, Accuracy: 80/103 (78%)\n",
            "Saved model to nouveau/model_33.pth. You can run `python evaluate.py --model nouveau/model_33.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 34 [0/1082 (0%)]\tLoss: 0.791921\n",
            "Train Epoch: 34 [320/1082 (29%)]\tLoss: 1.223084\n",
            "Train Epoch: 34 [640/1082 (59%)]\tLoss: 0.780958\n",
            "Train Epoch: 34 [960/1082 (88%)]\tLoss: 0.710413\n",
            "\n",
            "Validation set: Average loss: 0.0262, Accuracy: 82/103 (80%)\n",
            "Saved model to nouveau/model_34.pth. You can run `python evaluate.py --model nouveau/model_34.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 35 [0/1082 (0%)]\tLoss: 0.940934\n",
            "Train Epoch: 35 [320/1082 (29%)]\tLoss: 0.638372\n",
            "Train Epoch: 35 [640/1082 (59%)]\tLoss: 0.966268\n",
            "Train Epoch: 35 [960/1082 (88%)]\tLoss: 0.958304\n",
            "\n",
            "Validation set: Average loss: 0.0272, Accuracy: 79/103 (77%)\n",
            "Saved model to nouveau/model_35.pth. You can run `python evaluate.py --model nouveau/model_35.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 36 [0/1082 (0%)]\tLoss: 0.837189\n",
            "Train Epoch: 36 [320/1082 (29%)]\tLoss: 1.058852\n",
            "Train Epoch: 36 [640/1082 (59%)]\tLoss: 0.885461\n",
            "Train Epoch: 36 [960/1082 (88%)]\tLoss: 0.874582\n",
            "\n",
            "Validation set: Average loss: 0.0254, Accuracy: 82/103 (80%)\n",
            "Saved model to nouveau/model_36.pth. You can run `python evaluate.py --model nouveau/model_36.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 37 [0/1082 (0%)]\tLoss: 0.990222\n",
            "Train Epoch: 37 [320/1082 (29%)]\tLoss: 0.991186\n",
            "Train Epoch: 37 [640/1082 (59%)]\tLoss: 0.927222\n",
            "Train Epoch: 37 [960/1082 (88%)]\tLoss: 1.060646\n",
            "\n",
            "Validation set: Average loss: 0.0252, Accuracy: 81/103 (79%)\n",
            "Saved model to nouveau/model_37.pth. You can run `python evaluate.py --model nouveau/model_37.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 38 [0/1082 (0%)]\tLoss: 0.712648\n",
            "Train Epoch: 38 [320/1082 (29%)]\tLoss: 0.787440\n",
            "Train Epoch: 38 [640/1082 (59%)]\tLoss: 1.107468\n",
            "Train Epoch: 38 [960/1082 (88%)]\tLoss: 0.890385\n",
            "\n",
            "Validation set: Average loss: 0.0256, Accuracy: 82/103 (80%)\n",
            "Saved model to nouveau/model_38.pth. You can run `python evaluate.py --model nouveau/model_38.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 39 [0/1082 (0%)]\tLoss: 0.833977\n",
            "Train Epoch: 39 [320/1082 (29%)]\tLoss: 1.014344\n",
            "Train Epoch: 39 [640/1082 (59%)]\tLoss: 0.691161\n",
            "Train Epoch: 39 [960/1082 (88%)]\tLoss: 0.906905\n",
            "\n",
            "Validation set: Average loss: 0.0254, Accuracy: 82/103 (80%)\n",
            "Saved model to nouveau/model_39.pth. You can run `python evaluate.py --model nouveau/model_39.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 40 [0/1082 (0%)]\tLoss: 0.825941\n",
            "Train Epoch: 40 [320/1082 (29%)]\tLoss: 0.839437\n",
            "Train Epoch: 40 [640/1082 (59%)]\tLoss: 0.834493\n",
            "Train Epoch: 40 [960/1082 (88%)]\tLoss: 0.909668\n",
            "\n",
            "Validation set: Average loss: 0.0248, Accuracy: 84/103 (82%)\n",
            "Saved model to nouveau/model_40.pth. You can run `python evaluate.py --model nouveau/model_40.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 41 [0/1082 (0%)]\tLoss: 0.464263\n",
            "Train Epoch: 41 [320/1082 (29%)]\tLoss: 0.848570\n",
            "Train Epoch: 41 [640/1082 (59%)]\tLoss: 0.801930\n",
            "Train Epoch: 41 [960/1082 (88%)]\tLoss: 0.729954\n",
            "\n",
            "Validation set: Average loss: 0.0248, Accuracy: 81/103 (79%)\n",
            "Saved model to nouveau/model_41.pth. You can run `python evaluate.py --model nouveau/model_41.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 42 [0/1082 (0%)]\tLoss: 0.908374\n",
            "Train Epoch: 42 [320/1082 (29%)]\tLoss: 0.743918\n",
            "Train Epoch: 42 [640/1082 (59%)]\tLoss: 1.117730\n",
            "Train Epoch: 42 [960/1082 (88%)]\tLoss: 1.202563\n",
            "\n",
            "Validation set: Average loss: 0.0244, Accuracy: 81/103 (79%)\n",
            "Saved model to nouveau/model_42.pth. You can run `python evaluate.py --model nouveau/model_42.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 43 [0/1082 (0%)]\tLoss: 0.856702\n",
            "Train Epoch: 43 [320/1082 (29%)]\tLoss: 0.686203\n",
            "Train Epoch: 43 [640/1082 (59%)]\tLoss: 0.636311\n",
            "Train Epoch: 43 [960/1082 (88%)]\tLoss: 0.698954\n",
            "\n",
            "Validation set: Average loss: 0.0253, Accuracy: 80/103 (78%)\n",
            "Saved model to nouveau/model_43.pth. You can run `python evaluate.py --model nouveau/model_43.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 44 [0/1082 (0%)]\tLoss: 0.933132\n",
            "Train Epoch: 44 [320/1082 (29%)]\tLoss: 0.661057\n",
            "Train Epoch: 44 [640/1082 (59%)]\tLoss: 0.793756\n",
            "Train Epoch: 44 [960/1082 (88%)]\tLoss: 0.876590\n",
            "\n",
            "Validation set: Average loss: 0.0245, Accuracy: 84/103 (82%)\n",
            "Saved model to nouveau/model_44.pth. You can run `python evaluate.py --model nouveau/model_44.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 45 [0/1082 (0%)]\tLoss: 0.806924\n",
            "Train Epoch: 45 [320/1082 (29%)]\tLoss: 0.907531\n",
            "Train Epoch: 45 [640/1082 (59%)]\tLoss: 0.993953\n",
            "Train Epoch: 45 [960/1082 (88%)]\tLoss: 1.088626\n",
            "\n",
            "Validation set: Average loss: 0.0254, Accuracy: 80/103 (78%)\n",
            "Saved model to nouveau/model_45.pth. You can run `python evaluate.py --model nouveau/model_45.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 46 [0/1082 (0%)]\tLoss: 0.930683\n",
            "Train Epoch: 46 [320/1082 (29%)]\tLoss: 0.841995\n",
            "Train Epoch: 46 [640/1082 (59%)]\tLoss: 0.882312\n",
            "Train Epoch: 46 [960/1082 (88%)]\tLoss: 0.720680\n",
            "\n",
            "Validation set: Average loss: 0.0236, Accuracy: 84/103 (82%)\n",
            "Saved model to nouveau/model_46.pth. You can run `python evaluate.py --model nouveau/model_46.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 47 [0/1082 (0%)]\tLoss: 0.654869\n",
            "Train Epoch: 47 [320/1082 (29%)]\tLoss: 0.770762\n",
            "Train Epoch: 47 [640/1082 (59%)]\tLoss: 0.798048\n",
            "Train Epoch: 47 [960/1082 (88%)]\tLoss: 1.025188\n",
            "\n",
            "Validation set: Average loss: 0.0251, Accuracy: 80/103 (78%)\n",
            "Saved model to nouveau/model_47.pth. You can run `python evaluate.py --model nouveau/model_47.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 48 [0/1082 (0%)]\tLoss: 0.701472\n",
            "Train Epoch: 48 [320/1082 (29%)]\tLoss: 0.720565\n",
            "Train Epoch: 48 [640/1082 (59%)]\tLoss: 0.488669\n",
            "Train Epoch: 48 [960/1082 (88%)]\tLoss: 0.782024\n",
            "\n",
            "Validation set: Average loss: 0.0243, Accuracy: 82/103 (80%)\n",
            "Saved model to nouveau/model_48.pth. You can run `python evaluate.py --model nouveau/model_48.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 49 [0/1082 (0%)]\tLoss: 0.923137\n",
            "Train Epoch: 49 [320/1082 (29%)]\tLoss: 0.807085\n",
            "Train Epoch: 49 [640/1082 (59%)]\tLoss: 0.870212\n",
            "Train Epoch: 49 [960/1082 (88%)]\tLoss: 0.646099\n",
            "\n",
            "Validation set: Average loss: 0.0236, Accuracy: 83/103 (81%)\n",
            "Saved model to nouveau/model_49.pth. You can run `python evaluate.py --model nouveau/model_49.pth` to generate the Kaggle formatted csv file\n",
            "\n",
            "Train Epoch: 50 [0/1082 (0%)]\tLoss: 0.647266\n",
            "Train Epoch: 50 [320/1082 (29%)]\tLoss: 1.034082\n",
            "Train Epoch: 50 [640/1082 (59%)]\tLoss: 0.608258\n",
            "Train Epoch: 50 [960/1082 (88%)]\tLoss: 0.729071\n",
            "\n",
            "Validation set: Average loss: 0.0241, Accuracy: 83/103 (81%)\n",
            "Saved model to nouveau/model_50.pth. You can run `python evaluate.py --model nouveau/model_50.pth` to generate the Kaggle formatted csv file\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y22Kuw0D8-ED",
        "colab_type": "code",
        "outputId": "e3b8fea2-e6ec-446c-dc11-0fd691759d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import argparse\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import PIL.Image as Image\n",
        "\n",
        "import torch\n",
        "\n",
        "parser = argparse.ArgumentParser(description='RecVis A3 evaluation script')\n",
        "parser.add_argument('--data', type=str, default='bird_dataset', metavar='D',\n",
        "                    help=\"folder where data is located. test_images/ need to be found in the folder\")\n",
        "parser.add_argument('--model', type=str, metavar='M',\n",
        "                    help=\"the model file to be evaluated. Usually it is of the form model_X.pth\")\n",
        "parser.add_argument('--outfile', type=str, default='experiment/kaggle.csv', metavar='D',\n",
        "                    help=\"name of the output csv file\")\n",
        "\n",
        "#args = parser.parse_args()\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "state_dict = torch.load(\"/content/nouveau/model_30.pth\")\n",
        "model = model\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "if use_cuda:\n",
        "    print('Using GPU')\n",
        "    model.cuda()\n",
        "else:\n",
        "    print('Using CPU')\n",
        "\n",
        "#from data import data_transforms\n",
        "\n",
        "test_dir = 'bird_dataset' + '/test_images/mistery_category'\n",
        "\n",
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(path, 'rb') as f:\n",
        "        with Image.open(f) as img:\n",
        "            return img.convert('RGB')\n",
        "\n",
        "\n",
        "output_file = open('kaggle.csv', \"w\")\n",
        "output_file.write(\"Id,Category\\n\")\n",
        "for f in tqdm(os.listdir(test_dir)):\n",
        "    if 'jpg' in f:\n",
        "        data = data_val_transforms(pil_loader(test_dir + '/' + f))\n",
        "        data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "        output = model(data)\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        output_file.write(\"%s,%d\\n\" % (f[:-4], pred))\n",
        "\n",
        "output_file.close()\n",
        "\n",
        "print(\"Succesfully wrote \" + ', you can upload this file to the kaggle competition website')\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 4/517 [00:00<00:16, 31.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using GPU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 517/517 [00:14<00:00, 35.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Succesfully wrote , you can upload this file to the kaggle competition website\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}